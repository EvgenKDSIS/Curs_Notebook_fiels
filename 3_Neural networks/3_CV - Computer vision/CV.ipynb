{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGw5VCH1qaM9"
   },
   "source": [
    "# Задание\n",
    "Выполните следующие задания:\n",
    "\n",
    "> 1. Лёгкий уровень (Задание не обязательно к выполнению)\n",
    "Запишите видео с собой (допустим, держащим лист с надписью «1Т») из примера ноутбука занятия. Вставьте скриншот себя в ваш ноутбук с кодом (вы должны быть обведены в зеленый квадрат, детектированы нейронной сетью как в скринкастах), на котором будут видны сопровождающие надписи вокруг рамки видео: «Захват изображения...\"» и «Чтобы завершить...».\n",
    "\n",
    "Примечание: Если вам некомфортно снимать себя и прикладывать скриншот к ноутбуку, можете использовать какое-либо видео из интернета.\n",
    "\n",
    "> 2. PRO уровень (Задание не обязательно к выполнению)\n",
    "Доработав код захвата видео с камеры, сделайте запись видео с собой сегментированным, выводящим рукой надпись «1Т». Приложите ту часть кода на Python, которая ответственна за создание файла видео. Так же, как и в легком уровне, приложите скриншот сегментированного человека (это можете быть вы или какое-либо видео с человеком).\n",
    "\n",
    "Примечание: Если вам некомфортно снимать себя и прикладывать скриншот к ноутбуку, можете использовать какое-либо видео из интернета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biWGeHQ2tgk0",
    "outputId": "1b8f44db-3afd-4160-c693-ec735f6328c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.145)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.27.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2022.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->ultralytics) (16.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzglS4xLmw7k"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "1. Лёгкий уровень (Задание не обязательно к выполнению) Запишите видео с собой (допустим, держащим лист с надписью «1Т») из примера ноутбука занятия. Вставьте скриншот себя в ваш ноутбук с кодом (вы должны быть обведены в зеленый квадрат, детектированы нейронной сетью как в скринкастах), на котором будут видны сопровождающие надписи вокруг рамки видео: «Захват изображения...\"» и «Чтобы завершить...»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-j75lyxNpr1r"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "from IPython.display import Image as Image2\n",
    "from IPython import display\n",
    "from google.colab.output import eval_js\n",
    "from google.colab.patches import cv2_imshow\n",
    "from base64 import b64decode, b64encode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time\n",
    "import torch\n",
    "from PIL import Image as Image1\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUMqKCbUrwpG",
    "outputId": "31a2cb5d-9084-422a-a8e9-f99fdf2a240f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "WARNING ⚠️ 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING ⚠️ 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n",
      "YOLOv5 🚀 2023-7-30 Python-3.10.6 torch-2.0.1+cu118 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Using torch 2.0.1+cu118 (CPU), OpenCV: 4.7.0\n"
     ]
    }
   ],
   "source": [
    "detector = torch.hub.load('ultralytics/yolov5', 'custom', path = 'yolov5m.pt') #'yolov5s.pt'\n",
    "print('#'*60)\n",
    "print(f\"Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'}), OpenCV: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1bOMBEOyv5OV"
   },
   "outputs": [],
   "source": [
    "coco_labels = '''person\n",
    "bicycle\n",
    "car\n",
    "motorcycle\n",
    "airplane\n",
    "bus\n",
    "train\n",
    "truck\n",
    "boat\n",
    "traffic light\n",
    "fire hydrant\n",
    "street sign\n",
    "stop sign\n",
    "parking meter\n",
    "bench\n",
    "bird\n",
    "cat\n",
    "dog\n",
    "horse\n",
    "sheep\n",
    "cow\n",
    "elephant\n",
    "bear\n",
    "zebra\n",
    "giraffe\n",
    "hat\n",
    "backpack\n",
    "umbrella\n",
    "shoe\n",
    "eye glasses\n",
    "handbag\n",
    "tie\n",
    "suitcase\n",
    "frisbee\n",
    "skis\n",
    "snowboard\n",
    "sports ball\n",
    "kite\n",
    "baseball bat\n",
    "baseball glove\n",
    "skateboard\n",
    "surfboard\n",
    "tennis racket\n",
    "bottle\n",
    "plate\n",
    "wine glass\n",
    "cup\n",
    "fork\n",
    "knife\n",
    "spoon\n",
    "bowl\n",
    "banana\n",
    "apple\n",
    "sandwich\n",
    "orange\n",
    "broccoli\n",
    "carrot\n",
    "hot dog\n",
    "pizza\n",
    "donut\n",
    "cake\n",
    "chair\n",
    "couch\n",
    "potted plant\n",
    "bed\n",
    "mirror\n",
    "dining table\n",
    "window\n",
    "desk\n",
    "toilet\n",
    "door\n",
    "tv\n",
    "laptop\n",
    "mouse\n",
    "remote\n",
    "keyboard\n",
    "cell phone\n",
    "microwave\n",
    "oven\n",
    "toaster\n",
    "sink\n",
    "refrigerator\n",
    "blender\n",
    "book\n",
    "clock\n",
    "vase\n",
    "scissors\n",
    "teddy bear\n",
    "hair drier\n",
    "toothbrush\n",
    "hair brush'''.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Cju3_cQzvBrk"
   },
   "outputs": [],
   "source": [
    "def js_to_image(js_reply):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        js_reply: JavaScript object containing image from webcam\n",
    "    Returns:\n",
    "        img: OpenCV BGR image\n",
    "    \"\"\"\n",
    "    # декодируем изображение из формата base64\n",
    "    image_bytes = b64decode(js_reply.split(',')[1])\n",
    "    # конвертируем байты в numpy array\n",
    "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "    # декодируем numpy array в изображение OpenCV BGR image\n",
    "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
    "    return img\n",
    "\n",
    "# функция для преобразования изображения с прямоугольником OpenCV Rectangle bounding box image в байтовую строку base64 чтобы вывести в видеопоток\n",
    "def bbox_to_bytes(bbox_array):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
    "    Returns:\n",
    "          bytes: Base64 image byte string\n",
    "    \"\"\"\n",
    "    # конвертируем массив в изображение PIL image\n",
    "    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
    "    iobuf = io.BytesIO()\n",
    "    # преобразуем bbox в формат png для возврата из функции с помощью return\n",
    "    bbox_PIL.save(iobuf, format='png')\n",
    "    # форматируем возвращаемую с помощью return строку\n",
    "    bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
    "    return bbox_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9f5WtTIJvC7P"
   },
   "outputs": [],
   "source": [
    "# Используем код на JavaScript для захвата потока с нашей вебкамеры и передачи данных на облачный компьютер - надо запускать также для следующего раздела\n",
    "def video_stream_js():\n",
    "    js = Javascript('''\n",
    "    var video;\n",
    "    var div = null;\n",
    "    var stream;\n",
    "    var captureCanvas;\n",
    "    var imgElement;\n",
    "    var labelElement;\n",
    "\n",
    "    var pendingResolve = null;\n",
    "    var shutdown = false;\n",
    "\n",
    "    function removeDom() {\n",
    "       stream.getVideoTracks()[0].stop();\n",
    "       video.remove();\n",
    "       div.remove();\n",
    "       video = null;\n",
    "       div = null;\n",
    "       stream = null;\n",
    "       imgElement = null;\n",
    "       captureCanvas = null;\n",
    "       labelElement = null;\n",
    "    }\n",
    "\n",
    "    function onAnimationFrame() {\n",
    "      if (!shutdown) {\n",
    "        window.requestAnimationFrame(onAnimationFrame);\n",
    "      }\n",
    "      if (pendingResolve) {\n",
    "        var result = \"\";\n",
    "        if (!shutdown) {\n",
    "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
    "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
    "        }\n",
    "        var lp = pendingResolve;\n",
    "        pendingResolve = null;\n",
    "        lp(result);\n",
    "      }\n",
    "    }\n",
    "\n",
    "    async function createDom() {\n",
    "      if (div !== null) {\n",
    "        return stream;\n",
    "      }\n",
    "\n",
    "      div = document.createElement('div');\n",
    "      div.style.border = '2px solid black';\n",
    "      div.style.padding = '3px';\n",
    "      div.style.width = '100%';\n",
    "      div.style.maxWidth = '600px';\n",
    "      document.body.appendChild(div);\n",
    "\n",
    "      const modelOut = document.createElement('div');\n",
    "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
    "      labelElement = document.createElement('span');\n",
    "      labelElement.innerText = 'No data';\n",
    "      labelElement.style.fontWeight = 'bold';\n",
    "      modelOut.appendChild(labelElement);\n",
    "      div.appendChild(modelOut);\n",
    "\n",
    "      video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      video.width = div.clientWidth - 6;\n",
    "      video.setAttribute('playsinline', '');\n",
    "      video.onclick = () => { shutdown = true; };\n",
    "      stream = await navigator.mediaDevices.getUserMedia(\n",
    "          {video: { facingMode: \"environment\"}});\n",
    "      div.appendChild(video);\n",
    "\n",
    "      imgElement = document.createElement('img');\n",
    "      imgElement.style.position = 'absolute';\n",
    "      imgElement.style.zIndex = 1;\n",
    "      imgElement.onclick = () => { shutdown = true; };\n",
    "      div.appendChild(imgElement);\n",
    "\n",
    "      const instruction = document.createElement('div');\n",
    "      instruction.innerHTML =\n",
    "          '<span style=\"color: red; font-weight: bold;\">' +\n",
    "          'Чтобы завершить, щёлкните мышкой на данном видео</span>';\n",
    "      div.appendChild(instruction);\n",
    "      instruction.onclick = () => { shutdown = true; };\n",
    "\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      captureCanvas = document.createElement('canvas');\n",
    "      captureCanvas.width = 640; //video.videoWidth;\n",
    "      captureCanvas.height = 480; //video.videoHeight;\n",
    "      window.requestAnimationFrame(onAnimationFrame);\n",
    "\n",
    "      return stream;\n",
    "    }\n",
    "    async function stream_frame(label, imgData) {\n",
    "      if (shutdown) {\n",
    "        removeDom();\n",
    "        shutdown = false;\n",
    "        return '';\n",
    "      }\n",
    "\n",
    "      var preCreate = Date.now();\n",
    "      stream = await createDom();\n",
    "\n",
    "      var preShow = Date.now();\n",
    "      if (label != \"\") {\n",
    "        labelElement.innerHTML = label;\n",
    "      }\n",
    "\n",
    "      if (imgData != \"\") {\n",
    "        var videoRect = video.getClientRects()[0];\n",
    "        imgElement.style.top = videoRect.top + \"px\";\n",
    "        imgElement.style.left = videoRect.left + \"px\";\n",
    "        imgElement.style.width = videoRect.width + \"px\";\n",
    "        imgElement.style.height = videoRect.height + \"px\";\n",
    "        imgElement.src = imgData;\n",
    "      }\n",
    "\n",
    "      var preCapture = Date.now();\n",
    "      var result = await new Promise(function(resolve, reject) {\n",
    "        pendingResolve = resolve;\n",
    "      });\n",
    "      shutdown = false;\n",
    "\n",
    "      return {'create': preShow - preCreate,\n",
    "              'show': preCapture - preShow,\n",
    "              'capture': Date.now() - preCapture,\n",
    "              'img': result};\n",
    "    }\n",
    "    ''')\n",
    "    \n",
    "    display.display(js)\n",
    "\n",
    "def video_frame(label, bbox):\n",
    "    data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "OxVdQgXPvNoO",
    "outputId": "eaca372c-b34a-483e-ef33-6fc12c6d981c"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    var video;\n",
       "    var div = null;\n",
       "    var stream;\n",
       "    var captureCanvas;\n",
       "    var imgElement;\n",
       "    var labelElement;\n",
       "\n",
       "    var pendingResolve = null;\n",
       "    var shutdown = false;\n",
       "\n",
       "    function removeDom() {\n",
       "       stream.getVideoTracks()[0].stop();\n",
       "       video.remove();\n",
       "       div.remove();\n",
       "       video = null;\n",
       "       div = null;\n",
       "       stream = null;\n",
       "       imgElement = null;\n",
       "       captureCanvas = null;\n",
       "       labelElement = null;\n",
       "    }\n",
       "\n",
       "    function onAnimationFrame() {\n",
       "      if (!shutdown) {\n",
       "        window.requestAnimationFrame(onAnimationFrame);\n",
       "      }\n",
       "      if (pendingResolve) {\n",
       "        var result = \"\";\n",
       "        if (!shutdown) {\n",
       "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
       "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
       "        }\n",
       "        var lp = pendingResolve;\n",
       "        pendingResolve = null;\n",
       "        lp(result);\n",
       "      }\n",
       "    }\n",
       "\n",
       "    async function createDom() {\n",
       "      if (div !== null) {\n",
       "        return stream;\n",
       "      }\n",
       "\n",
       "      div = document.createElement('div');\n",
       "      div.style.border = '2px solid black';\n",
       "      div.style.padding = '3px';\n",
       "      div.style.width = '100%';\n",
       "      div.style.maxWidth = '600px';\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const modelOut = document.createElement('div');\n",
       "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
       "      labelElement = document.createElement('span');\n",
       "      labelElement.innerText = 'No data';\n",
       "      labelElement.style.fontWeight = 'bold';\n",
       "      modelOut.appendChild(labelElement);\n",
       "      div.appendChild(modelOut);\n",
       "\n",
       "      video = document.createElement('video');\n",
       "      video.style.display = 'block';\n",
       "      video.width = div.clientWidth - 6;\n",
       "      video.setAttribute('playsinline', '');\n",
       "      video.onclick = () => { shutdown = true; };\n",
       "      stream = await navigator.mediaDevices.getUserMedia(\n",
       "          {video: { facingMode: \"environment\"}});\n",
       "      div.appendChild(video);\n",
       "\n",
       "      imgElement = document.createElement('img');\n",
       "      imgElement.style.position = 'absolute';\n",
       "      imgElement.style.zIndex = 1;\n",
       "      imgElement.onclick = () => { shutdown = true; };\n",
       "      div.appendChild(imgElement);\n",
       "\n",
       "      const instruction = document.createElement('div');\n",
       "      instruction.innerHTML =\n",
       "          '<span style=\"color: red; font-weight: bold;\">' +\n",
       "          'Чтобы завершить, щёлкните мышкой на данном видео</span>';\n",
       "      div.appendChild(instruction);\n",
       "      instruction.onclick = () => { shutdown = true; };\n",
       "\n",
       "      video.srcObject = stream;\n",
       "      await video.play();\n",
       "\n",
       "      captureCanvas = document.createElement('canvas');\n",
       "      captureCanvas.width = 640; //video.videoWidth;\n",
       "      captureCanvas.height = 480; //video.videoHeight;\n",
       "      window.requestAnimationFrame(onAnimationFrame);\n",
       "\n",
       "      return stream;\n",
       "    }\n",
       "    async function stream_frame(label, imgData) {\n",
       "      if (shutdown) {\n",
       "        removeDom();\n",
       "        shutdown = false;\n",
       "        return '';\n",
       "      }\n",
       "\n",
       "      var preCreate = Date.now();\n",
       "      stream = await createDom();\n",
       "\n",
       "      var preShow = Date.now();\n",
       "      if (label != \"\") {\n",
       "        labelElement.innerHTML = label;\n",
       "      }\n",
       "\n",
       "      if (imgData != \"\") {\n",
       "        var videoRect = video.getClientRects()[0];\n",
       "        imgElement.style.top = videoRect.top + \"px\";\n",
       "        imgElement.style.left = videoRect.left + \"px\";\n",
       "        imgElement.style.width = videoRect.width + \"px\";\n",
       "        imgElement.style.height = videoRect.height + \"px\";\n",
       "        imgElement.src = imgData;\n",
       "      }\n",
       "\n",
       "      var preCapture = Date.now();\n",
       "      var result = await new Promise(function(resolve, reject) {\n",
       "        pendingResolve = resolve;\n",
       "      });\n",
       "      shutdown = false;\n",
       "\n",
       "      return {'create': preShow - preCreate,\n",
       "              'show': preCapture - preShow,\n",
       "              'capture': Date.now() - preCapture,\n",
       "              'img': result};\n",
       "    }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# получаем прямоугольники(баундбоксы) - в кадре должен быть человек\n",
    "# очищаем память\n",
    "gc.collect()\n",
    "\n",
    "# начинаем захват видео с камеры\n",
    "video_stream_js()\n",
    "\n",
    "# Создаём надпись\n",
    "label_html = 'Захват изображения...'\n",
    "\n",
    "# инициализируем пустые прямоугольники выделения\n",
    "bbox = ''\n",
    "count = 0\n",
    "while True:\n",
    "    js_reply = video_frame(label_html, bbox)\n",
    "    if not js_reply:\n",
    "        break\n",
    "\n",
    "    # конвертируем поток, передаваемый через JS, в изображение OpenCV Image\n",
    "    img = js_to_image(js_reply[\"img\"])\n",
    "\n",
    "    # создаём пустой массив, в котором будет отображаться детекция объектов\n",
    "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
    "\n",
    "    # переводим изображение в серое для детекции\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # детектирование\n",
    "    cur = detector(img) #img\n",
    "    yolo_preds = cur.xyxy[0].cpu().numpy()\n",
    "\n",
    "    # получение коодинат прямоугольников\n",
    "    boxes = yolo_preds[:, :4]  # xmin, ymin, xmax, ymax\n",
    "    confs = yolo_preds[:, 4]\n",
    "    labels = yolo_preds[:, 5]\n",
    "\n",
    "    fst_box_flag = 1\n",
    "\n",
    "    # получаем конкретные прямоугольники\n",
    "    for box, conf, label in zip(boxes, confs, labels):\n",
    "        if coco_labels[int(label)] == 'person' and fst_box_flag == 1: #\n",
    "            y1, y2, x1, x2 = int(box[1]), int(box[3]), int(box[0]), int(box[2])\n",
    "            bbox_array = cv2.rectangle(bbox_array,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            fst_box_flag = 0\n",
    "\n",
    "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
    "\n",
    "    bbox_bytes = bbox_to_bytes(bbox_array) #bbox_array\n",
    "    # записываем в конкретные массивы изображения с прямоугольниками\n",
    "    bbox = bbox_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводим фото**\n",
    "![Снимок](./снимок.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaFMJZs_nSb2"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "2. PRO уровень (Задание не обязательно к выполнению) Доработав код захвата видео с камеры, сделайте запись видео с собой сегментированным, выводящим рукой надпись «1Т». Приложите ту часть кода на Python, которая ответственна за создание файла видео. Так же, как и в легком уровне, приложите скриншот сегментированного человека (это можете быть вы или какое-либо видео с человеком).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border:solid blue 2px; padding: 20px'>\n",
    "Прошу сделать разбор PRO части на вебинаре\n",
    "    (Тема крутая, но недопонимание огромное)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2Ipt6ysB0Q0o"
   },
   "outputs": [],
   "source": [
    "# Функция для добавления надписи на изображение\n",
    "def add_text(image):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text = '1Т'\n",
    "    org = (50, 50)  # Координаты начала надписи\n",
    "    font_scale = 2\n",
    "    color = (255, 255, 255)  # Цвет текста (белый)\n",
    "    thickness = 2\n",
    "    image = cv2.putText(image, text, org, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "# Захват видео с камеры\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Задаем формат видео и FPS\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Указываем имя файла видео и параметры записи\n",
    "out = cv2.VideoWriter('segmented_video.avi', fourcc, fps, (640, 480))\n",
    "\n",
    "# Загружаем модель сегментации\n",
    "#net = cv2.dnn.readNetFromCaffe('path/to/model.prototxt', 'path/to/model.caffemodel')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Обработка кадра\n",
    "\n",
    "    # Размещение надписи \"1Т\"\n",
    "    frame = add_text(frame)\n",
    "\n",
    "    # Записываем кадр в файл видео\n",
    "    out.write(frame)\n",
    "\n",
    "    cv2.imshow('Segmented Video', frame)  # Отображение видео на экране\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
